{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_path = '/content/drive/MyDrive/CART498/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfAfj9sEeOv2",
        "outputId": "74c03278-9db3-4fd7-c86f-f425e95da074"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\").to(\"cuda\")\n",
        "model.eval()\n",
        "\n",
        "# Suppress informational messages and warnings\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "OTt79NaUaPtJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_oulipian_poem(poem, x, seed):\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    new_poem = \"\"\n",
        "\n",
        "    for line in poem.strip().split(\"\\n\"):\n",
        "        # Split the line into everything before the last word\n",
        "        before, last_token = line.rsplit(\" \", 1)\n",
        "\n",
        "        # Extract the word and punctuation from the last token\n",
        "        match = re.match(r\"(.+?)([^\\w\\s]*)$\", last_token)\n",
        "        last_word, punctuation = match.groups()\n",
        "\n",
        "        # Create prompt and get model predictions\n",
        "        prompt = before + \" \" + last_word\n",
        "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids).logits[0, -1]\n",
        "\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        # Get the top x predictions to ensure we have enough\n",
        "        top_probs, top_indices = torch.topk(probs, k=min(x + 5, len(probs)))\n",
        "\n",
        "        # Select the x-th ranked token\n",
        "        if x - 1 < len(top_indices):\n",
        "            predicted_token = top_indices[x - 1]\n",
        "        else:\n",
        "            predicted_token = top_indices[-1]  # Fallback to last available\n",
        "\n",
        "        predicted_word = tokenizer.decode([predicted_token]).strip()\n",
        "\n",
        "        new_poem += before + \" \" + predicted_word + punctuation + \"\\n\"\n",
        "\n",
        "    return new_poem\n",
        "\n"
      ],
      "metadata": {
        "id": "VCQ5SD_kd5mW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poem = \"\"\"\n",
        "One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "PJuceLeWetXp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate P+7 version\n",
        "prediction_level = 7\n",
        "oulipian_poem = generate_oulipian_poem(poem, prediction_level, seed=0)\n",
        "with open(f'{drive_path}P+7.txt', 'w') as f:\n",
        "    f.write(oulipian_poem)\n",
        "print(oulipian_poem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82bSECdIfmHQ",
        "outputId": "d293b7f0-3e93-49b4-a05e-33e10ee13bb9",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One must have a mind of that\n",
            "To regard the frost and the and\n",
            "Of the pine-trees crusted with that;\n",
            "And have been cold a long in\n",
            "To behold the junipers shagged with as,\n",
            "The spruces rough in the distant -\n",
            "Of the January sun; and not to I\n",
            "Of any misery in the sound of the that,\n",
            "In the sound of a few coming,\n",
            "Which is the sound of the in\n",
            "Full of the same as\n",
            "That is blowing in the same bare ,\"\n",
            "For the listener, who listens in the ?,\n",
            "And, nothing himself, what\n",
            "Nothing that is not there and the nothing that here.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate P+23 version\n",
        "prediction_level = 23\n",
        "oulipian_poem_px = generate_oulipian_poem(poem, prediction_level, seed=0)\n",
        "with open(f'{drive_path}P+{prediction_level}.txt', 'w') as f:\n",
        "    f.write(oulipian_poem_px)\n",
        "print(oulipian_poem_px)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3r_zb0pzobEx",
        "outputId": "b385ac8b-6072-45e9-b581-d3aa54e371dd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One must have a mind of on\n",
            "To regard the frost and the it\n",
            "Of the pine-trees crusted with m;\n",
            "And have been cold a long â€¦\n",
            "To behold the junipers shagged with while,\n",
            "The spruces rough in the distant ings\n",
            "Of the January sun; and not to but\n",
            "Of any misery in the sound of the :,\n",
            "In the sound of a few hitting,\n",
            "Which is the sound of the crashing\n",
            "Full of the same is\n",
            "That is blowing in the same bare we\n",
            "For the listener, who listens in the outside,\n",
            "And, nothing himself, you\n",
            "Nothing that is not there and the nothing that on.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}